3.2.2 Introspection: Guiding Safety with Generated Self-Critiques
We propose Introspection a novel intervention method designed specifically for the CARE framework. Instead of directly manipulating the model’s output distribution Introspection prompts the LLM to reflect on its own mistake and generate a self-critical statement which is then used to guide a safer regeneration.
 When a rollback is triggered we use the following prompt template to elicit an introspective response from the model:
 You are a safe and responsible language model. When responding to a user’s harmful request you may have generated content that was inappropriate or could lead to improper associations. Next please reflect briefly and provide a self-criticism. Start your response with "…oh I’m sorry I just realized".
 The conversation history for this instance is:
 User Query: {q} Your Prior Response: {r(t)}
 The model’s self-critical generation (e.g. "…oh I’m sorry I just realized that providing such information would be harmful…") is then used to fill the new buffer steering the subsequent generation onto a safer trajectory. This method leverages the emergent meta-cognitive capabilities of LLMs for a more natural and interpretable form of safety alignment. We provide several case studies in Appendix F[ref_id]A6 that illustrate this intervention process on practical examples of harmful user requests.