1 Introduction
The rapid advancements in LMs in recent years have significantly broadened their applications extending beyond natural language tasks to more complex challenges such as web navigation~\cite{bib.bib38} data extraction~\cite{bib.bib24} and tool use~\cite{bib.bib28}. Unlike traditional natural language processing (NLP) tasks where the output is aimed at review by humans output in these applications is often consumed by machines such as controller and service APIs. The machine-oriented nature of these applications requires LMs to generate structured outputs that strictly adhere to predefined formats and constraints. However the LM generation process is probabilistic and does not provide guarantees on the output’s structure making it challenging to deploy LMs in applications requiring structured inputs and high reliability.
 The methodology of constrained decoding a technique that integrates constraints into the decoding process of LMs has been developed to address the need to adapt LM generations to the challenge of providing structured output. Constrained decoding intervenes in the decoding process of LMs by masking out invalid tokens based on given constraints and prefix tokens. This intervention guides the LM to sample only from valid tokens ensuring that the final output perfectly conforms to a predefined structure.
 The strong demand for structured generation~\cite{bib.bib22} has led to the development of various constrained-decoding frameworks1We use the terms constrained decoding framework and grammar engine interchangeably. such as Guidance~\cite{bib.bib14} Outlines~\cite{bib.bib35} XGrammar~\cite{bib.bib8} and the grammar module of Llamacpp~\cite{bib.bib11} These frameworks provide broad support for different types of constraints minimal overhead and compatibility with various LM ecosystems facilitating the adoption of constrained decoding in real-world applications.
 JSON Schema offers a high level domain-specific way to define constraints for JSON data a widely adopted data interchange format. As a result JSON Schema has emerged as a key specification language for constrained decoding. Commercial LM providers such as OpenAI have embraced constrained decoding by incorporating support for JSON Schema directly into their APIs. These integrations highlight the emergence of JSON Schema as an industry-wide standard for specifying constraints on structured outputs ensuring compatibility across diverse applications.
 Despite the growing adoption of constrained decoding for structured generation several issues and questions persist: Q1: Efficiency: Does constrained decoding slow down or speed up the generation process? Which framework is the most efficient? Q2: Coverage: The JSON Schema specification has an evolving and expansive feature set. How well do existing constrained decoding frameworks support these features?  Q3: Quality: While constrained decoding guarantees that LM outputs conform to a desired structure does it negatively affect the semantic quality of outputs?
 To answer these questions we need to study constrained-decoding methods with a large-scale diverse and real-world collection of user-defined structures. To evaluate the performance of constrained decoding frameworks we introduce JSONSchemaBench a collection of 10K real-world JSON schemas from various sources Organized into 10 datasets of varying complexity and diversity the benchmark spans domains such as function signatures service APIs and system configurations. We evaluate six state-of-the-art constrained decoding frameworks including Guidance Outlines Llamacpp XGrammar OpenAI and Gemini on JSONSchemaBench. We pair this real-world schema dataset with the official JSON Schema Test Suite~\cite{bib.bib17} in order to extract detailed insights into coverage of JSON Schema functionality across these frameworks and to further evaluate them with considerations of end-to-end task accuracy in the context of multiple real-world tasks. Altogether our evaluation takes three aspects into consideration: efficiency coverage and quality. We define specific metrics to measure these three functional aspects and evaluate constrained decoding frameworks against them. Through extensive experiments we converge on the following findings as illustrated in Figure 1. (1) Constrained decoding can speed up the generation process by 50% compared to unconstrained decoding. (2) Frameworks demonstrate significant differences in their actual support for real-world JSON schemas with the best framework supporting twice as many schemas as the worst. (3) Constrained decoding consistently improves the performance of downstream tasks up to 4% even for tasks with minimal structure like GSM8k.
[IMAGE START] [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/35f6f9de0227925a436ca8218cc12e20.png] Figure 1: Comparison across various constrained-decoding frameworks by
efficiency (speed of output generation), coverage (support for JSON Schema features), and quality (effects on underlying task accuracy). Guidance outperforms other frameworks on these dimensions.[IMAGE END]



## Section References
[bib.bib38] Yao et al. (2023b) Shunyu Yao Jeffrey Zhao Dian Yu Nan Du Izhak Shafran Karthik Narasimhan and Yuan Cao. ReAct: Synergizing reasoning and acting in language models. In International Conference on Learning Representations (ICLR) 2023b.
[bib.bib24] Polak & Morgan (2024) Maciej P. Polak and Dane Morgan. Extracting accurate materials data from research papers with conversational language models and prompt engineering. Nature Communications 15(1) February 2024. ISSN 2041-1723. doi: 10.1038/s41467-024-45914-8. URL http://dx.doi.org/10.1038/s41467-024-45914-8.
[bib.bib28] Schick et al. (2023) Timo Schick Jane Dwivedi-Yu Roberto Dessi Roberta Raileanu Maria Lomeli Eric Hambro Luke Zettlemoyer Nicola Cancedda and Thomas Scialom. Toolformer: Language Models Can Teach Themselves to Use Tools. In A. Oh T. Naumann A. Globerson K. Saenko M. Hardt and S. Levine (eds.) Advances in Neural Information Processing Systems volume 36 pp. 68539–68551. Curran Associates Inc. 2023. URL https://proceedings.neurips.cc/paper_files/paper/2023/file/d842425e4bf79ba039352da0f658a906-Paper-Conference.pdf.
[bib.bib22] Liu et al. (2024) Michael Xieyang Liu Frederick Liu Alexander J. Fiannaca Terry Koo Lucas Dixon Michael Terry and Carrie J. Cai. "We Need Structured Output": Towards User-centered Constraints on Large Language Model Output. In Extended Abstracts of the CHI Conference on Human Factors in Computing Systems pp. 1–9 May 2024. doi: 10.1145/3613905.3650756. URL http://arxiv.org/abs/2404.07362. arXiv:2404.07362 [cs].
[bib.bib14] Guidance AI (2023) Guidance AI. Guidance: A language model programming framework 2023. URL https://github.com/guidance-ai/guidance. Accessed: 2024-12-18.
[bib.bib35] Willard & Louf (2023) Brandon T. Willard and Rémi Louf. Efficient Guided Generation for Large Language Models August 2023. URL http://arxiv.org/abs/2307.09702. arXiv:2307.09702 [cs].
[bib.bib8] Dong et al. (2024) Yixin Dong Charlie F. Ruan Yaxing Cai Ruihang Lai Ziyi Xu Yilong Zhao and Tianqi Chen. XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models November 2024. URL http://arxiv.org/abs/2411.15100. arXiv:2411.15100 [cs].
[bib.bib11] Gerganov & al. (2023) Georgi Gerganov and al. Llama.cpp: A port of facebook’s llama model in c++. https://github.com/ggerganov/llama.cpp 2023. Accessed: 2025-01-16.
[bib.bib17] JSON Schema Org (2024) JSON Schema Org. Json schema test suite. https://github.com/json-schema-org/JSON-Schema-Test-Suite 2024. URL https://github.com/json-schema-org/JSON-Schema-Test-Suite. Accessed: 2024-12-19.