2 Background and Related Work
JSON Schema is a meta-language that describes the structure of JSON data. It is capable of expressing a wide variety of constraints such as the types of JSON object properties the length of JSON arrays or the pattern that a JSON string must match. The syntax and capabilities of JSON Schema are defined in the JSON Schema specification~\cite{bib.bib36} which defines a large number of keywords each of which may be used or combined with other keywords within a schema to enforce constraints like the ones mentioned. JSON Schema is widely used in the software ecosystem and previous work has been done to collect extensive examples of JSON Schemas with a focus both on real-world use as well as on overall correctness.
 ~\cite{bib.bib3} collected over 6000 JSON schemas from publicly available GitHub repositories. ~\cite{bib.bib2} used it alongside additional collected JSON schemas in order to evaluate a witness generation algorithm for JSON Schema. Separately the official JSON Schema Test Suite~\cite{bib.bib17} is a collection of manually created test cases maintained by the JSON Schema core team which exercises a large portion of the functionality defined in the JSON Schema specification. It was originally written to assist implementers of JSON Schema validation tools with testing their compliance against the specification and therefore contains a wide variety of examples for each of JSON Schema’s keywords including in edge case scenarios. Notably Bowtie~\cite{bib.bib6} leverages the test suite as a foundation for comparing and understanding different implementations of the JSON Schema specification across programming languages. Taken together these two datasets form a large number of examples both of JSON Schema’s diverse feature set as well as its use in the wild.
 1:Constraint C LLM f Prompt x
 2:Output o adhering to C
 3:o\leftarrow[]
 4:loop
 5:  C.\texttt{update}(o) \triangleright advance state of C
 6:  m\leftarrow C.\texttt{mask} \triangleright compute mask
 7:  v\leftarrow f(x+o) \triangleright compute logits
 8:  v^{\prime}\leftarrow m\odot v^{\prime}
 9:  t\leftarrow\texttt{decode}(\alpha^{\prime}) \triangleright sample
 10:  ift=\text{EOS}then
 11:   break
 12:  endif
 13:  o.\texttt{append}(t)
 14:endloop
 15:return o \triangleright output
 Constrained decoding~\cite{bib.bib7 bib.bib30 bib.bib29 bib.bib23 bib.bib34 bib.bib9} refers to methods that guide the generation process of language models (LMs) by masking out tokens that do not adhere to predefined constraints at each step. Recently highly optimized grammar-constrained decoding frameworks~\cite{bib.bib14 bib.bib5 bib.bib35 bib.bib19 bib.bib39 bib.bib8} have been developed to improve the efficiency and usability of constrained decoding.
 The evaluation of constrained decoding remains an under-explored topic with no consensus on what defines the effectiveness of constrained decoding. While some research has pursued comparisons of constrained decoding with unconstrained LMs~\cite{bib.bib26 bib.bib32 bib.bib37} the studies to date fail to provide comparisons across different constrained decoding frameworks. The benchmarks employed have either narrowly focused on specific tasks or rely on formal-grammar–based artificial setups that have unclear relevance to real-world use cases.


## Section References
[bib.bib36] Wright et al. (2022) Austin Wright Henry Andrews Ben Hutton and Greg Dennis. Draft 2020-12: Json schema core specification. https://json-schema.org/draft/2020-12/json-schema-core.html 2022. Published 16 June 2022. Metaschema available at https://json-schema.org/draft/2020-12/schema.
[bib.bib3] Baazizi et al. (2021) Mohamed Amine Baazizi Dario Colazzo Giorgio Ghelli Carlo Sartiani and Stefanie Scherzinger. A json schema corpus 2021. https://github.com/sdbs-uni-p/json-schema-corpus.
[bib.bib2] Attouche et al. (2022) Lyes Attouche Mohamed-Amine Baazizi Dario Colazzo Giorgio Ghelli Carlo Sartiani and Stefanie Scherzinger. Witness Generation for JSON Schema. Proceedings of the VLDB Endowment 15(13):4002–4014 September 2022. ISSN 2150-8097. doi: 10.14778/3565838.3565852. URL https://dl.acm.org/doi/10.14778/3565838.3565852.
[bib.bib17] JSON Schema Org (2024) JSON Schema Org. Json schema test suite. https://github.com/json-schema-org/JSON-Schema-Test-Suite 2024. URL https://github.com/json-schema-org/JSON-Schema-Test-Suite. Accessed: 2024-12-19.
[bib.bib6] Bowtie (2025) Bowtie. Bowtie: A meta-validator of the json schema specification 2025. URL https://github.com/bowtie-json-schema/bowtie/. DOI: 10.5281/zenodo.14646449.
[bib.bib7] Deutsch et al. (2019) Daniel Deutsch Shyam Upadhyay and Dan Roth. A General-Purpose Algorithm for Constrained Sequential Inference. In Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL) pp. 482–492 Hong Kong China 2019. Association for Computational Linguistics. doi: 10.18653/v1/K19-1045. URL https://www.aclweb.org/anthology/K19-1045.
[bib.bib30] Shin et al. (2021) Richard Shin Christopher Lin Sam Thomson Charles Chen Subhro Roy Emmanouil Antonios Platanios Adam Pauls Dan Klein Jason Eisner and Benjamin Van Durme. Constrained Language Models Yield Few-Shot Semantic Parsers. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing pp. 7699–7715 Online and Punta Cana Dominican Republic November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.608. URL https://aclanthology.org/2021.emnlp-main.608.
[bib.bib29] Scholak et al. (2021) Torsten Scholak Nathan Schucher and Dzmitry Bahdanau. PICARD: Parsing incrementally for constrained auto-regressive decoding from language models. In Marie-Francine Moens Xuanjing Huang Lucia Specia and Scott Wen-tau Yih (eds.) Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing pp. 9895–9901 Online and Punta Cana Dominican Republic November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.779. URL https://aclanthology.org/2021.emnlp-main.779/.
[bib.bib23] Poesia et al. (2022) Gabriel Poesia Oleksandr Polozov Vu Le Ashish Tiwari Gustavo Soares Christopher Meek and Sumit Gulwani. Synchromesh: Reliable code generation from pre-trained language models January 2022. URL http://arxiv.org/abs/2201.11227. arXiv:2201.11227 [cs].
[bib.bib34] (34) Bailin Wang Zi Wang Xuezhi Wang Yuan Cao Rif A Saurous and Yoon Kim. Grammar Prompting for Domain-Specific Language Generation with Large Language Models.
[bib.bib9] Geng et al. (2023) Saibo Geng Martin Josifoski Maxime Peyrard and Robert West. Grammar-constrained decoding for structured NLP tasks without finetuning. In Houda Bouamor Juan Pino and Kalika Bali (eds.) Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing pp. 10932–10952 Singapore December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.674. URL https://aclanthology.org/2023.emnlp-main.674.
[bib.bib14] Guidance AI (2023) Guidance AI. Guidance: A language model programming framework 2023. URL https://github.com/guidance-ai/guidance. Accessed: 2024-12-18.
[bib.bib5] Beurer-Kellner et al. (2023) Luca Beurer-Kellner Marc Fischer and Martin Vechev. Prompting Is Programming: A Query Language for Large Language Models. Proceedings of the ACM on Programming Languages 7(PLDI):1946–1969 June 2023. ISSN 2475-1421. doi: 10.1145/3591300. URL http://arxiv.org/abs/2212.06094. arXiv:2212.06094 [cs].
[bib.bib35] Willard & Louf (2023) Brandon T. Willard and Rémi Louf. Efficient Guided Generation for Large Language Models August 2023. URL http://arxiv.org/abs/2307.09702. arXiv:2307.09702 [cs].
[bib.bib19] Kuchnik et al. (2023) Michael Kuchnik Virginia Smith and George Amvrosiadis. Validating Large Language Models with ReLM May 2023. URL http://arxiv.org/abs/2211.15458. arXiv:2211.15458 [cs].
[bib.bib39] Zheng et al. (2024) Lianmin Zheng Liangsheng Yin Zhiqiang Xie Chuyue Sun Jeff Huang Cody Hao Yu Shiyi Cao Christos Kozyrakis Ion Stoica Joseph E. Gonzalez Clark Barrett and Ying Sheng. SGLang: Efficient Execution of Structured Language Model Programs June 2024. URL http://arxiv.org/abs/2312.07104. arXiv:2312.07104 [cs].
[bib.bib8] Dong et al. (2024) Yixin Dong Charlie F. Ruan Yaxing Cai Ruihang Lai Ziyi Xu Yilong Zhao and Tianqi Chen. XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models November 2024. URL http://arxiv.org/abs/2411.15100. arXiv:2411.15100 [cs].
[bib.bib26] Roy et al. (2024) Subhro Roy Sam Thomson Tongfei Chen Richard Shin Adam Pauls Jason Eisner and Benjamin Van Durme. BenchCLAMP: A Benchmark for Evaluating Language Models on Syntactic and Semantic Parsing January 2024. URL http://arxiv.org/abs/2206.10668. arXiv:2206.10668 [cs].
[bib.bib32] Tang et al. (2024) Xiangru Tang Yiming Zong Jason Phang Yilun Zhao Wangchunshu Zhou Arman Cohan and Mark Gerstein. Struc-Bench: Are Large Language Models Good at Generating Complex Structured Tabular Data? In Kevin Duh Helena Gomez and Steven Bethard (eds.) Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers) pp. 12–34 Mexico City Mexico June 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.naacl-short.2. URL https://aclanthology.org/2024.naacl-short.2.
[bib.bib37] Yao et al. (2023a) Shunyu Yao Howard Chen Austin W. Hanjie Runzhe Yang and Karthik Narasimhan. COLLIE: Systematic Construction of Constrained Text Generation Tasks July 2023a. URL http://arxiv.org/abs/2307.08689. arXiv:2307.08689 [cs].