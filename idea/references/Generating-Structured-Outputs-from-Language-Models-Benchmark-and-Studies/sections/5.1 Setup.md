5.1 Setup
To measure empirical coverage we conduct all experiments using the Llama-3.2-1B-Instruct model as it is small enough to run efficiently while still producing high-quality outputs. The prompt consists of a simple instruction with two-shot examples (Figure 3[ref_id]A2.F3) and validation is performed using the jsonschema Python library (~\cite{bib.bib4}) (using JSON Schema Draft2020-12) with string-format checks enabled. We use greedy decoding with zero-temperature performing a single generation run and enforce a 40-second timeout for grammar compilation and an additional 40 seconds for generation. Exceeding these limits is treated as a schema processing failure. Additional details are provided in Appendix B[ref_id]A2.


## Section References
[bib.bib4] Berman (2025) Julian Berman. python-jsonschema. https://github.com/python-jsonschema/jsonschema 2025. URL https://github.com/python-jsonschema/jsonschema. Accessed: 2025-01-05.