5.3.1 Results


#### Coverage Analysis
Coverage Analysis
 For each grammar engine and category in the test suite we calculate test coverage as the proportion of passing test cases reported in Figure 6[ref_id]A4.F6 in Appendix D[ref_id]A4 Additionally Table 5[ref_id]S5.T5 aggregates these metrics counting categories with minimal coverage (> 0%) partial coverage (> 25%) moderate coverage (> 50%) high coverage (> 75%) and full coverage (100%). We indicate the number of categories for which each framework achieves the highest test coverage (either as the single highest or as the sole leader) as well as the number of categories for which each framework is the sole leader.
 •
 Overall Performance: Guidance outperforms other engines at all coverage levels achieving full coverage on 13 categories and moderate coverage on 21. In comparison Llamacpp and XGrammar have full coverage on only one category and moderate coverage on five and three categories respectively while Outlines has no full coverage on any category and moderate coverage on two categories.
 •
 Single Highest: Guidance has the single highest coverage in 19 categories followed by XGrammar with 10 and Outlines with one and Llamacpp with none.
 Coverage Outlines Llamacpp XGrammar Guidance
 Minimal coverage (>0%) 20 21 28 30
 Partial coverage (>25%) 11 11 16 25
 Moderate coverage (>50%) 2 5 3 21
 High coverage (>75%) 0 2 1 17
 Full coverage (100%) 0 1 1 13
 Tied for highest (>0%) 4 6 14 25
 Single highest 1 0 10 19

#### Failure Analysis
Failure Analysis
 Table 6[ref_id]S5.T6 provides a breakdown of failure modes for each framework across the test suite detailing the number of categories with compilation errors failures to generate positive instances (over-constrained) and failures to block negative instances (under-constrained).
 Failure type Outlines Llamacpp XGrammar Guidance
 Compile Error 42 37 3 25
 Over-constrained 16 18 5 7
 Under-constrained 8 7 38 1
 Overall Guidance demonstrates the fewest total failures in particular minimizing under-constrained errors. Outlines Llamacpp and Guidance follow a consistent failure pattern with most errors occurring during compilation and over-constrained failures being more frequent than under-constrained ones. In contrast XGrammar minimizes compilation errors but shows the highest number of under-constrained failures indicating a trade-off favoring permissiveness.
 We acknowledge that there is no straightforward correspondence between test suite performance and empirical coverage. One reason for this is that not all features are equally represented in real-world schemas. As a result strong or weak performance on specific features can have disproportionate impacts depending on their prevalence. Another reason is under-constraining effectively delegates responsibility to the LM which may produce valid output despite a lack of strict constraints. We emphasize that while under-constraining can be a legitimate strategy it requires careful implementation and transparency to ensure reliability.