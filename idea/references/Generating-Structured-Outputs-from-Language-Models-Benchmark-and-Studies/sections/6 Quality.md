6 Quality
In principle constrained decoding should not affect the quality of the generated output as it only filters out the invalid tokens. However things become more complicated due to ambiguity of tokenization~\cite{bib.bib33 bib.bib15 bib.bib10} and the distributional shifts caused by the intervention~\cite{bib.bib9 bib.bib31}. As a hypothetical toy example an LM might answer ‘89000’ instead of the correct ‘89000’ in a GSM8K question. Constrained decoding can block the invalid token ‘’ enforcing structural compliance but potentially may cause the LM to go out of distribution and generate ‘890000’ instead. ~\cite{bib.bib21} argued that the performance decline observed in previous studies~\cite{bib.bib31} comes from inadequate prompting insufficient contextual information and poorly crafted schemas.


## Section References
[bib.bib33] Vivien (2024) Vivien. Llm decoding with regex constraints. https://vivien000.github.io/blog/journal/llm-decoding-with-regex-constraints.html 2024. Accessed: 2024-12-21.
[bib.bib15] GuidanceAI (2024a) GuidanceAI. Prompt boundaries and token healing. https://github.com/guidance-ai/guidance/blob/main/notebooks/art_of_prompt_design/prompt_boundaries_and_token_healing.ipynb 2024a. Accessed: 2024-12-21.
[bib.bib10] Geng et al. (2024) Saibo Geng Sankalp Gambhir Chris Wendler and Robert West. Byte bpe tokenization as an inverse string homomorphism 2024. URL https://arxiv.org/abs/2412.03160.
[bib.bib9] Geng et al. (2023) Saibo Geng Martin Josifoski Maxime Peyrard and Robert West. Grammar-constrained decoding for structured NLP tasks without finetuning. In Houda Bouamor Juan Pino and Kalika Bali (eds.) Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing pp. 10932–10952 Singapore December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.674. URL https://aclanthology.org/2023.emnlp-main.674.
[bib.bib31] Tam et al. (2024) Zhi Rui Tam Cheng-Kuang Wu Yi-Lin Tsai Chieh-Yen Lin Hung-yi Lee and Yun-Nung Chen. Let me speak freely? a study on the impact of format restrictions on large language model performance. In Franck Dernoncourt Daniel Preoţiuc-Pietro and Anastasia Shimorina (eds.) Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Industry Track pp. 1218–1236 Miami Florida US November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.emnlp-industry.91. URL https://aclanthology.org/2024.emnlp-industry.91/.
[bib.bib21] Kurt (2024b) Will Kurt. Say what you mean: A response to ’let me speak freely’ 2024b. URL https://.txt.co/blog/say-what-you-mean-a-response-to-let-me-speak-freely.