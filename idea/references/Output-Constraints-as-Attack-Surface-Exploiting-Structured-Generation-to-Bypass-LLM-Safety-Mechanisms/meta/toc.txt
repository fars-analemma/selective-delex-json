abstract.md
1. Introduction.md
2. Preliminaries and Related Work.md
  2.1. Jailbreak Attacks on LLMs.md
  2.2. Constrained Decoding for LLMs.md
3. Motivation.md
4. Constrained Decoding Attacks.md
  4.1. Enum Attack A Proof-of-Concept.md
    4.1.1. Enum Attack on OpenAIâ€™s GPT models.md
  4.2. Chain Enum Attack Exploiting Shallow Alignment.md
  4.3. Discussions Other CDAs.md
5. Evaluation.md
  5.1. Experimental Setup.md
  5.2. Comprehensive Evaluation of Enum Attack.md
    5.2.1. Enum Attack on Open-Weight LLMs.md
    5.2.2. Enum Attack on Proprietary LLMs and the Best Open-Weight LLM.md
6. Discussions.md
7. Ethics Consideration.md
8. Conclusion.md
References.md