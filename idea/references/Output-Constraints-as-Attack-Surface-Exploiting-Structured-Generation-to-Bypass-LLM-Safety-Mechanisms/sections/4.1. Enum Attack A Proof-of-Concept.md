4.1. Enum Attack: A Proof-of-Concept
\Description
 Code to perform Enum Attack.
 First of all we craft a proof-of-concept attack namely Enum Attack to demonstrate the feasibility of Constrained Decoding Attacks in LLMs. We will illustrate how Enum Attack works and how it can be used to jailbreak the model using case studies. For quantitative evaluation we will extensively evaluate Enum Attack using multiple LLMs on multiple benchmarks in follow-up §5[ref_id]S5.
 Enum Attack can be applied to a wide range of models and infrastructures which support OpenAI-compatible API and its structured output features. As depicted in Figure8 this attack is an exploit of the response format field where a malicious JSON schema created using Pydantic~\cite{bib.bib62} is used to perform the real attack. The attacker can directly set a few fields in the JSON to be in the customizable enum space and the model is constrained to generate the enum strings in the output. Therefore the attacker can easily manipulate the output by constructing malicious enum strings to jailbreak the model.
 As directly shown in Figure8 within the designed JSON Schema the first field contains the actual malicious question while the input prompt uses harmless content that bypasses prompt auditing. The follow-up field of the JSON schema includes an affirmative prefix string that guides the model to begin with a positive response to the question. Finally the model’s output becomes dominated by the established malicious context. The model naturally continues generating step-by-step responses that answer the harmful question effectively completing the jailbreak attack against its safety guardrails.
[IMAGE START] [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/4b7994b4145df3404f770e6715b0cc54.png] Figure 8. Illustration code for Enum Attack, where the attack body is located in the structured output, and the prompt part is harmless, so it can bypass prompt-based auditing.[IMAGE END]



## Section References
[bib.bib62] Team (2020) Pydantic Team. 2020. JSON Schema - Pydantic. https://docs.pydantic.dev/latest/concepts/json_schema/. Accessed: March 14 2025.