5.2.2. Enum Attack on Proprietary LLMs and the Best Open-Weight LLM
Building upon our proof-of-concept demonstration in §§4.1[ref_id]S4.SS1 we now present a comprehensive cross-benchmark evaluation of Enum Attack. As shown in Table4 we systematically compare performance across five diverse safety benchmarks to thoroughly assess the attack’s generalizability. We compare the performance of the attack on three proprietary models and Phi-3.5-MoE the best aligned open-weight model during evaluation. To compare with we use direct prompting as the baseline.
 Baseline results confirm that direct prompting is largely ineffective against the safety alignment of modern LLMs. Although different benchmarks cover different aspects of harmful content the overall baseline ASR remains consistently low with averages of 8.0% (AdvBench) 36.75% (HarmBench) 16.75% (JailbreakBench) 35.86% (SorryBench) and 7.51% (StrongREJECT). The 4o-series models demonstrate particularly strong resistance to direct prompting on AdvBench and JailbreakBench with ASRs below 2%. These baseline measurements validate the effectiveness of conventional safety mechanisms against traditional attacks.
 As shown in Table4 our proof-of-concept Enum Attack is super effective in the same experimental settings except Gemini-2.0-flash model other models achieve at least 95% ASR on all 5 benchmarks with only a single query to attack even Gemini model achieve over 89% ASR on four benchmarks and 81.2% ASR on StrongREJECT the lowest ASR among all models. The results significantly indicate that current LLMs are vulnerable to Enum-based attacks and the safety alignment is not as effective as expected.
 We further take StrongREJECT score into account which measures the harmfulness of the generated text. The results show that Enum Attack not only succeeds in breaking the safety alignment but also generates highly harmful content as prompted. The average StrongREJECT Score of the attack is 88.9% 85.0% 82.8% and 73.7% on each model respectively. The results indicate that the generated text is highly convincing and specific which poses a significant threat to the safety and trustworthiness of LLMs.
 Particularly notable is the consistency of Phi-3.5-MoE’s lower StrongREJECT scores across all benchmarks despite high raw ASR. This cross-benchmark confirmation strengthens our earlier hypothesis about deep alignment~\cite{bib.bib50} providing partial mitigation to Enum Attack. While the attack still succeeds in technical terms (output is generated no direct refusal) the quality and harmfulness of that content is measurably reduced through parameter-level safety alignment.
 The evaluation results reveal a significant vulnerability in current LLM services with structured output features. Enum Attack and its simple variants can easily jailbreak models without extensive query attempts presenting a severe security threat. The results also confirm our earlier observation that alignment quality varies significantly across models with Phi-3.5-MoE demonstrating the most resilience during our evaluation though still fundamentally vulnerable.
 In conclusion the success of Enum Attack highlights a critical gap between current safety guardrails and the novel attack surface presented by constrained decoding exploitation.
[TABLE START]<table>
	<tr>
		<td rowspan="2">Type</td>
		<td rowspan="2">Model</td>
		<td rowspan="2">Method</td>
		<td colspan="2">AdvBench</td>
		<td colspan="2">HarmBench</td>
		<td colspan="2">JailbreakBench</td>
		<td colspan="2">SorryBench</td>
		<td colspan="2">StrongREJECT</td>
		<td colspan="2">Average</td>
	</tr>
	<tr>
		<td>ASR</td>
		<td>SR</td>
		<td>ASR</td>
		<td>SR</td>
		<td>ASR</td>
		<td>SR</td>
		<td>ASR</td>
		<td>SR</td>
		<td>ASR</td>
		<td>SR</td>
		<td>ASR</td>
		<td>SR</td>
	</tr>
	<tr>
		<td rowspan="6">Proprietary</td>
		<td rowspan="2">GPT-4o</td>
		<td>Baseline</td>
		<td>1.2%</td>
		<td>1.1%</td>
		<td>26.0%</td>
		<td>22.3%</td>
		<td>10.0%</td>
		<td>9.1%</td>
		<td>33.9%</td>
		<td>30.4%</td>
		<td>5.1%</td>
		<td>4.8%</td>
		<td>15.2%</td>
		<td>13.5%</td>
	</tr>
	<tr>
		<td>EnumAttack</td>
		<td>100.0%</td>
		<td>95.6%</td>
		<td>100.0%</td>
		<td>90.8%</td>
		<td>100.0%</td>
		<td>90.5%</td>
		<td>96.4%</td>
		<td>79.6%</td>
		<td>99.4%</td>
		<td>87.8%</td>
		<td>99.2%</td>
		<td>88.9%</td>
	</tr>
	<tr>
		<td rowspan="2">GPT-4o-mini</td>
		<td>Baseline</td>
		<td>2.1%</td>
		<td>1.8%</td>
		<td>44.0%</td>
		<td>39.1%</td>
		<td>14.0%</td>
		<td>13.1%</td>
		<td>42.5%</td>
		<td>39.8%</td>
		<td>8.9%</td>
		<td>8.0%</td>
		<td>22.3%</td>
		<td>20.4%</td>
	</tr>
	<tr>
		<td>EnumAttack</td>
		<td>99.0%</td>
		<td>91.5%</td>
		<td>100.0%</td>
		<td>86.5%</td>
		<td>97.0%</td>
		<td>85.9%</td>
		<td>96.4%</td>
		<td>75.9%</td>
		<td>98.1%</td>
		<td>85.2%</td>
		<td>98.1%</td>
		<td>85.0%</td>
	</tr>
	<tr>
		<td rowspan="2">Gemini-2.0</td>
		<td>Baseline</td>
		<td>17.5%</td>
		<td>13.0%</td>
		<td>46.0%</td>
		<td>41.3%</td>
		<td>22.0%</td>
		<td>19.8%</td>
		<td>29.3%</td>
		<td>26.7%</td>
		<td>6.0%</td>
		<td>4.2%</td>
		<td>24.2%</td>
		<td>21.0%</td>
	</tr>
	<tr>
		<td>EnumAttack</td>
		<td>95.8%</td>
		<td>93.2%</td>
		<td>92.0%</td>
		<td>85.5%</td>
		<td>92.0%</td>
		<td>85.0%</td>
		<td>89.5%</td>
		<td>75.4%</td>
		<td>81.2%</td>
		<td>74.8%</td>
		<td>90.1%</td>
		<td>82.8%</td>
	</tr>
	<tr>
		<td rowspan="3">Open</td>
		<td rowspan="3">Phi-3.5-MoE</td>
		<td>Baseline</td>
		<td>11.5%</td>
		<td>10.6%</td>
		<td>31.0%</td>
		<td>27.3%</td>
		<td>21.0%</td>
		<td>19.1%</td>
		<td>37.7%</td>
		<td>33.5%</td>
		<td>9.9%</td>
		<td>8.7%</td>
		<td>22.2%</td>
		<td>19.8%</td>
	</tr>
	<tr>
		<td>EnumAttack</td>
		<td>99.2%</td>
		<td>76.9%</td>
		<td>98.0%</td>
		<td>74.6%</td>
		<td>95.0%</td>
		<td>72.3%</td>
		<td>98.4%</td>
		<td>70.1%</td>
		<td>96.5%</td>
		<td>74.8%</td>
		<td>97.4%</td>
		<td>73.7%</td>
	</tr>
	<tr>
		<td>ChainEnumAttack</td>
		<td>100.0%</td>
		<td>87.6%</td>
		<td>100.0%</td>
		<td>83.1%</td>
		<td>100.0%</td>
		<td>82.0%</td>
		<td>98.8%</td>
		<td>77.9%</td>
		<td>99.2%</td>
		<td>84.5%</td>
		<td>99.6%</td>
		<td>83.0%</td>
	</tr>
</table>
Table 4. Attack Success Rate (ASR) and StrongREJECT score (SR) evaluation with EnumAttack across multiple benchmarks. In each column, Red indicates the highest attack results, Green indicates the lowest attack results. Additionally, we perform ChainEnumAttack on Phi-3.5-MoE with GPT-4o’s output.[TABLE END]



## Section References
[bib.bib50] Qi et al. (2025) Xiangyu Qi Ashwinee Panda Kaifeng Lyu Xiao Ma Subhrajit Roy Ahmad Beirami Prateek Mittal and Peter Henderson. 2025. Safety Alignment Should be Made More Than Just a Few Tokens Deep. In The Thirteenth International Conference on Learning Representations. https://openreview.net/forum?id=6Mxhg9PtDE