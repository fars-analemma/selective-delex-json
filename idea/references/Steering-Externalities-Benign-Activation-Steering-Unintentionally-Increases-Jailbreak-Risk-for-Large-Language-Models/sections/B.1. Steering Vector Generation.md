B.1. Steering Vector Generation
• STEER-COMPLIANCE: As discussed in Sec. 3, we follow the behavior vector generation procedure inspired by CAST ~\cite{b11}. However, while the original CAST implementation generates vectors meant to drive the model toward refusal behavior, our approach differs. We utilize 100 benign questions from the Alpaca dataset, pairing each with both a compliance and a refusal response. For example, for a benign question such as Given a sentence, please provide the proper punctuation, we attach an affirmative response and a refusal response (e.g., I regret to inform you that I can't). Instead of steering in the refusal direction, we utilize PCA to identify the first principal direction toward compliance. • STEER-JSON: We utilize instruction-following prompts to generate a steering vector that controls the format of the LLM's response. Specifically, following the methodology in ~\cite{b23}, we construct a dataset of paired prompts using 400 questions sampled from IFEVAL. Unlike STEER COMPLIANCE, these instruction pairs contrast the presence of a formatting constraint. For example: -List 3 fruits. -List 3 fruits in JSON format. By extracting the mean difference between the hidden states of these paired instructions, we steer the LLM to be more likely to generate responses in JSON format.

Section references:
[b11]: B Lee, I Padhi, K Ramamurthy, E Miehling, P Dognin, M Nagireddy, A Dhurandhar. Programming refusal with conditional activation steering. (2025). Programming refusal with conditional activation steering
[b23]: A Stolfo, V Balachandran, S Yousefi, E Horvitz, B Nushi. Improving instruction-following in language models through activation steering. (2025). Improving instruction-following in language models through activation steering