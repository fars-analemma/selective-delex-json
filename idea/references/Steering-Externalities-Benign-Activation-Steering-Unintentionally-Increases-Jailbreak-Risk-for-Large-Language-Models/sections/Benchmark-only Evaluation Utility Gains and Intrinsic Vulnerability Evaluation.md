Benchmark-only Evaluation: Utility Gains and Intrinsic Vulnerability Evaluation
We first confirmed that both steering interventions achieved their intended benign utility goals. As shown in Table 1, STEER-COMPLIANCE reduces refusals on harmless Alpaca prompts across all evaluated models, consistent with improved compliance/helpfulness. Similarly, STEER-JSON increases the fraction of JSON-valid outputs on IFEval, indicating improved format-following utility. Benchmark-only safety evaluation (no jailbreak attack). Next, we evaluated intrinsic safety regressions in a benchmark-only setting: we prompted the model with harmful HarmBench queries directly (without any adaptive jailbreak algorithm) and measured ASR with the HarmBench classifier. Figure 2 (left) shows that both steering methods increased ASR relative to the original aligned models across all tested LLMs. Notably, STEER-COMPLIANCE yields the largest regressions (e.g., Llama-3-8B-Instruct increased from a 2% baseline ASR to 38.5%), while even purely syntactic STEER-JSON increased ASR substantially (e.g., Llama-2-7B-Chat increases from 0% to 11.5%). These results indicated that benign utility steering can itself constitute an intrinsic vulnerability-a form of steering externality-even before introducing any jailbreak attack procedure. In Appendix C, we also reported refusal-rate shifts on a different harmful benchmark, SorryBench (Xie et al., 2025).