Bypassing the Refusal Gate via Autoregressive Inertia
One plausible mechanism is that, because we inject the steering vector into the residual stream during decoding, activation steering can change the model's internal state-and thus the next-token distribution-from the very first generated token. Under autoregressive generation, this prefix-level shift can then propagate and yield a qualitatively different completion. Concretely, LLMs generate text autoregressively, where the probability of a full response y given a harmful input x factorizes over tokens y t : P (y | x) = T t=1 P (y t | x, y <t ). (6) Under the "Shallow Safety Alignment" hypothesis ~\cite{b21}, safety behavior is concentrated in a short prefix window t ∈ [1, k] that effectively decides whether the model enters a refusal or non-refusal mode. This lets us decompose generation into an early gate and a continuation phase: P (y | x) = P (y ≤k | x) Refusal Gate • P (y >k | x, y ≤k ) Autoregressive Inertia . (7) A standard aligned model assigns high probability to refusalprefixed openings in the first k tokens; once a refusal prefix is sampled, the continuation distribution is conditioned on that prefix and naturally stays on a safe trajectory. Activation steering intervenes by shifting hidden states, and its most safety-critical effect can occur during this prefix decision: it moves probability mass away from refusal markers and toward compliant or structured openers, increasing the chance that the model begins in a non-refusal mode (quantified at the token level in Sec. 5.2). After this point, autoregressive inertia propagates the altered trajectory: later tokens are conditioned on the non-refusal prefix, and the model tends to continue coherently-potentially generating harmful content that was not deeply suppressed by training. Importantly, observing token-level changes during generation is not sufficient to fully assess safety. Even if steering only alters the early prefix, the meaning of the response can continue to evolve as generation unfolds, and an apparently benign opening can still lead to an unsafe completion. This motivates a complementary representation-level perspective that evaluates the model after it has committed to a trajectory: activation steering can shift the hidden representations of harmful requests (and their evolving context) toward regions typically associated with harmless queries, thereby shrinking the safety margin in hidden space (Sec. 5.3). Taken together, token-level effects capture how steering influences decisions during autoregressive sampling, while representation-level effects capture how steering reshapes the semantic state after a trajectory is established-jointly explaining how benign steering can bypass refusal behavior without removing any explicit safety mechanism.

Section references:
[b21]: X Qi, A Panda, K Lyu, X Ma, S Roy, A Beirami, P Mittal, P Henderson. Safety alignment should be made more than just a few tokens deep. (2024). Safety alignment should be made more than just a few tokens deep