G. STEER-BIND Results
We explore a safety-aware steering-vector construction strategy that reduces the safety regressions induced by pure compliance steering. Concretely, we construct a mixed dataset (STEER-BIND) by randomly sampling 50 benign instructions from Alpaca and 50 harmful prompts from BeaverTails ~\cite{b9}, then assigning the desired behavior conditionally by prompt type: benign prompts are paired with compliant continuations, while harmful prompts are paired with refusal continuations. We then apply the CAST procedure ~\cite{b11} to extract principal steering direction. Empirically, STEER-BIND substantially reduces the externality of STEER-COMPLIANCE on Llama-3-8B-Instruct: benchmark-only ASR drops from 36% (STEER-COMPLIANCE) to 5% (STEER-BIND), and CoP ASR drops from 93% to 76% (Table 5). The trade-off is a small reduction in harmless utility relative to pure compliance steering: harmless refusal increases from 0% (STEER-COMPLIANCE) to 1% (STEER-BIND), though it remains below the original model's refusal rate of 2%. Overall, these results suggest that injecting a small amount of safety-aware data into the steering-vector construction pipeline can attenuate steering externalities under both benchmark-only and adaptive jailbreak evaluations.

[TABLE START]Table 5 . STEER-BIND: safety-aware mixed steering partially mitigates the safety regressions induced by compliance steering on Llama-3-8B-Instruct, while largely preserving harmless utility. <table><row><cell>Llama-3-8B-Instruct 2%</cell><cell>1%</cell><cell>4%</cell><cell>5%</cell><cell>36%</cell><cell>73%</cell><cell>76%</cell><cell>93%</cell></row></table>[TABLE END]


Section references:
[b11]: B Lee, I Padhi, K Ramamurthy, E Miehling, P Dognin, M Nagireddy, A Dhurandhar. Programming refusal with conditional activation steering. (2025). Programming refusal with conditional activation steering
[b9]: J Ji, M Liu, J Dai, X Pan, C Zhang, C Bian, C Zhang, R Sun, Y Wang, Y Yang. Beavertails: Towards improved safety alignment of llm via a human-preference dataset. (2023). Beavertails: Towards improved safety alignment of llm via a human-preference dataset