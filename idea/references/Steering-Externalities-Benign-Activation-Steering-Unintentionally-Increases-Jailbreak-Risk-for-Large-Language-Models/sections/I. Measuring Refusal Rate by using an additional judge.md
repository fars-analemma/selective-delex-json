I. Measuring Refusal Rate by using an additional judge
In this section, we utilize a different refusal judge, Sorrybench fine-tuned Mistral-7B-Instruct-v0.2, to measure the overall refusal rate. Specifically, we employ the Sorry-Bench fine-tuned Mistral-7B-v0.2 model to judge refusal rate/harmfulness, providing a complementary perspective to the Roberta-based evaluation used in Sec. 4. As shown in Table 7, the safety regression is particularly severe for Llama-3-8B-Instruct, where the refusal rate plummets from 86% to 30%, and Gemma-7B-it, which drops from 90% to 68%. Even Llama-2-7B-Chat, which appears more robust, exhibits a non-trivial decrease in refusal rates. This indicates that the "compliance" direction identified by the steering vectors does not discriminate between benign and malicious requests; rather, it broadly suppresses the model's refusal mechanisms. Consequently, while activation steering successfully enhances the model's helpful-  Table 9 shows that even when the original models exhibit a 0% benchmark-only ASR, applying STEER-COMPLIANCE introduces a measurable intrinsic safety regression (0%→2% on Llama-3-8B-Instruct-RR, and 0%→6% on GPT-OSS-20B). While these absolute increases are small in the benchmark-only regime, they indicate that compliance-oriented steering can partially erode refusal behavior even without any adaptive attack. More importantly, the synergistic effect under blackbox jailbreaking is substantial: when combined with CoP, STEER-COMPLIANCE increases ASR by 18% on Llama-3-8B-Instruct-RR (52%→70%) and by 22% points on GPT-OSS-20B (62%→84%). This mirrors our main finding that benign compliance steering acts as a force multiplier for adaptive jailbreak pipelines: even a modest reduction in refusal robustness can be amplified by an attacker that iteratively searches for prompts that elicit non-refusal trajectories. These additional results support that benign STEER-COMPLIANCE might unintentionally loosen the safety guardrails leading to harmful generation

[TABLE START]Table 7 . Refusal Rate between original target LLMs and compliance steered LLMs on Harmful SorryBench data using fine-tuned Mistral as Judge. After steering, all LLMs have a lower refusal rate than the original model. <table><row><cell>Models</cell><cell cols="2">Original Refusal Rate Compliance Steered Refsual Rate (SorryBench Judge)</cell></row><row><cell>Llama-2-7B-Chat</cell><cell>90.00%</cell><cell>83.00%</cell></row><row><cell>Llama-3-8B-Instruct</cell><cell>86.00%</cell><cell>30.00%</cell></row><row><cell>Gemma-7B-it</cell><cell>90.00%</cell><cell>68.00%</cell></row></table>[TABLE END]
