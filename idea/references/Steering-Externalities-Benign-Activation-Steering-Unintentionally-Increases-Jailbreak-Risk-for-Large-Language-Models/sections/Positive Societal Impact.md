Positive Societal Impact
Our work highlights a critical blind spot in current model deployment pipelines: that model developers optimize for benign intentions like "helpfulness/compliance" or "instruction adherence" can accidentally erode safety guardrails. By demonstrating that "shallow" safety alignment can be bypassed through internal representation shifts, we motivate the research community to move beyond surface-level refusal training. This work encourages the development of more robust alignment techniques that persist deeper into the generation trajectory and necessitates the inclusion of steering evaluations in safety audits before deployment.