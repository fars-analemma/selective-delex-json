Synergistic
Vulnerability Evaluation: Benign Steering Amplifies Jailbreak Vulnerability Section 4.2 showed that benign steering increased vulnerability even without jailbreak attacks. Here, we evaluated whether steering amplifies black-box jailbreak pipelines such as CoP, PAIR, and TAP (Xiong et al., 2025; Chao et al., 2023; Mehrotra et al., 2023) on HarmBench. Amplification of Existing Jailbreak Attacks. We first examined CoP attack on 400 HarmBench samples. Figure 2 (right) revealed a compounding effect: steering made existing attacks significantly more potent. For STEER-COMPLIANCE, the effect is drastic. In the case of Llama-2-7B-Chat, while the CoP attack alone achieved a 77% ASR, combining it with compliance steering pushed the ASR to a near-total compromise of 95%. Similarly, Gemma-7B-it reached an ASR of 93.5% under the combined setting. Crucially, this amplification is not limited to helpfulness optimization; STEER-JSON also acts as a force multiplier for jailbreaks. When the CoP attack is combined with JSON steering, Llama-2-7B-Chat sees its ASR rise to 88.75%, a significant jump over the baseline attack. Likewise, Gemma-7B-it reached an ASR of 90.3% under the combined condition. These results indicated that both steering lower the defense barrier, allowing jailbreak techniques more likely to succeed. Generalization across Attack Methods. To ensure these findings are not specific to a single attack method, we extended our evaluation to the PAIR and TAP attacks on Llama-2-7B-Chat using a subset of 50 HarmBench samples. As detailed in Table 2, steering mechanisms visibly degraded the model's resistance to the PAIR attack. STEER-COMPLIANCE doubled the effectiveness of the attack on Llama-2-7B-Chat, raising the ASR from 10% to 20%. STEER-JSON also compromised safety, though to a lesser degree, increasing the ASR to 14%. Similarly, the TAP attack became more potent under steering influence. Compliance steering increased the success rate by 14%, resulting in a final ASR of 34%. JSON steering exhibits a similar trend, boosting the ASR to 26% (+6%). These results confirmed that even formatting-focused interventions can weaken the model's safety margin. Our results show that activation steering-even for benign purposes-introduces severe safety risks, a phenomenon we term "steering externalities." This technique inherently increases harmful output generation and amplifies vulnerability to adversarial jailbreaking attacks. To understand why benign activation steering compromises safety in our experiments, we provide a mechanistic analysis at two coupled levels: (i) a token-level analysis of how steering reshapes the distribution over the first few generated tokens that decide whether the model enters a refusal or non-refusal mode (Sec. 5.1 and Sec. 5.2), and (ii) a representation-level analysis showing that steering shifts the hidden-state encodings of harmful prompts toward regions typically associated with harmless requests, reducing the effective safety margin in hidden space (Sec. 5.3).

[TABLE START]Table 2 . Attack Success Rate (ASR) by applying black-box jailbreak attacks PAIR and TAP on original and steered models respectively on 50 Harmbench questions. After steering, all LLMs are more vulnerable to jailbreak attacks. <table><row><cell>Model</cell><cell>Attack Methods</cell><cell cols="3">Original Compliance Steered JSON Steered ASR ASR ASR</cell></row><row><cell>Llama-2-7B-Chat</cell><cell>PAIR TAP</cell><cell>10% 20%</cell><cell>20% (+10) 34% (+14)</cell><cell>14% (+4) 26% (+6)</cell></row><row><cell cols="5">5. Why Would Activation Steering Cause</cell></row><row><cell cols="2">Misalignment?</cell><cell/><cell/><cell/></row></table>[TABLE END]
